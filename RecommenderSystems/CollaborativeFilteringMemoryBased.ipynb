{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering based Recommender System\n",
    "\n",
    "<figure style=\"display: block; margin-left: auto; margin-right: auto; width: 90%; text-align: center;\">\n",
    "  <img src=\"figures/recommender_systems.png\" alt=\"Recommender Systems.\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are one of the most successful and widespread application of machine learning technologies in industry. The ability to suggest products with most appealing factor to each consumer type of your clients base is trivial not only to keep your clients engaged, but to atract new costumers. The business model and success of big companys like Netflix, Amazon, Steam, Spotify, YouTube and many others, revolves around the potency of their *Recommender Systems*.\n",
    "\n",
    "A recommender system deals with the task of predict the degree of similarity between items (movies, songs, clothing, shoes, etc) or users in a database. Based on these similarities the system can provide personalized *recommendations* of items for users.\n",
    "\n",
    "Generally speaking, recommender systems can be classified into 3 types:\n",
    "\n",
    "* **Collaborative Filtering based:** These systems predict the rating or preference that a user would give an item based on past user ratings or preferences. No item metadata is required, in contrast to its content-based counterparts.\n",
    "\n",
    "* **Content-based Filtering:** These systems predict the item rating or user preference based on item metadata (genre, director, description, actors, color, etc) and user preferences and history. These systems dependes highly on item metadata.\n",
    "\n",
    "* **Hybrid systems:** These systems try to leverage the best of both worlds and constitutes a wide range of state-of-art techniques in industry. These are complex systems, usually made of multiple smaller subsystems.\n",
    "\n",
    "Those system types have their own pros and cons. In this post we'll implement a simple Collaborative Filtering based system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "As said before, Collabortative Filtering (CF) is a type of recommendation technique that uses similarities between users (or items) to infer the possible level of interest of a user to a item unrated by him. These similarities are computed using sonenly existing user ratings for items. Thus specific item description metadata is not needed.\n",
    "\n",
    "There are two general CF approaches:\n",
    "\n",
    "* **User-based**, which exploits similarities between **users**. A rating prediction of an user to an item is computed using the item ratings given by similar users.\n",
    "* **Item-based**, which exploits similarities between **items**. A rating prediction of an user to an item is computed using ratings of similar items.\n",
    "<figure style=\"display: block; margin-left: auto; margin-right: auto; width: 90%; text-align: center;\">\n",
    "  <img src=\"figures/CF_approachs.png\" alt=\"CF approaches.\">\n",
    "    <figcaption>Collaborative Filtering approaches.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both cases, the first step to build the system is to compute an **interactions matrix**, where each row contains the ratings given by a user to all items in database, and each columns contains the ratings given by all users to an specific item.\n",
    "\n",
    "Figure below illustrate an example interactions matrix. User ratings are in range 1 to 5. A rating 0 means that this specific item was not rated by this specific user.\n",
    "\n",
    "<figure style=\"display: block; margin-left: auto; margin-right: auto; width: 90%; text-align: center;\">\n",
    "  <img src=\"figures/sample_iter_mat.png\" alt=\"Example interaction matrix\">\n",
    "  <figcaption>Example interaction matrix</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **interactions matrix** is, naturally, an *sparse matrix*: in practical scenarios, the majority of the users may not have rated the majority of the items. This may lead to adoption of specific algorithms to deal with sparse data.\n",
    "\n",
    "Two main algorithm types are used to implement recommender systems (either item-based or user-based):\n",
    "\n",
    "* **Memory based**, in which statistical techniques are applied to the entire dataset to calculate the rating predictions.\n",
    "\n",
    "* **Model based**, which involve steps to reduce or compress the large, but possibly sparse, interactions matrix.\n",
    "\n",
    "In this post, we'll use a *memory based* strategy, which is simpler to explain and easier to understand. In a future post we'll cover the implementation of a *model based* approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/3273eabb-9e14-47b4-8ddd-ddb77dddcd30/workspace/DataScienceMiniProjects/RecommenderSystems/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MovieLens 100K Dataset\n",
    "\n",
    "There are a number of datasets available for recommendations systems research. Amongst them, the [MovieLens](https://grouplens.org/datasets/movielens) dataset is probably one of the more popular ones. MovieLens is a non-commercial web-based movie recommender system, created in 1997 and run by the GroupLens Research Project, at University of Minnesota. It's data has been critical for several research studies including personalized recommendation and social psychology.\n",
    "\n",
    "There are several versions of the dataset available. We'll use the well-known [MovieLens 100k](https://grouplens.org/datasets/movielens/100k/), which consists of 100,000 ratings form 943 users on 1682 movies. Some simple demographic information such as age, gender, genres for the users and items are also available, but we'll not use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"ml-100k\"):\n",
    "    # # Download the dataset\n",
    "    !wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "    # # Unzip it\n",
    "    !unzip ml-100k.zip\n",
    "    # # Get rid of the .zip file\n",
    "    !rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset folder contains several files, but we need only two of them:\n",
    "\n",
    "* **u.data**: The full dataset with 100,000 user ratings. Each user has rated at least 20 movies.\n",
    "* **u.item**: Contains informations about the movies, but we will use only movies ids and titles. This data is not required for the understanding of the CF technique, but we will use it for a more friendly feedback of our system.\n",
    "\n",
    "Let's begin by loading the ratings dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating\n",
       "0          196       242       3\n",
       "1          186       302       3\n",
       "2           22       377       1\n",
       "3          244        51       2\n",
       "4          166       346       1\n",
       "...        ...       ...     ...\n",
       "99995      880       476       3\n",
       "99996      716       204       5\n",
       "99997      276      1090       1\n",
       "99998       13       225       2\n",
       "99999       12       203       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\n",
    "    \"ml-100k/u.data\",\n",
    "    sep=\"\\t\", # this is a tab separated data\n",
    "    names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"], # the columns names\n",
    "    usecols=[\"user_id\", \"movie_id\", \"rating\"], # we do not need the timestamp column\n",
    "    low_memory=False\n",
    ")\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry consists in a *user_id*, *movie_id* and a movie *rating* in range of 1 to 5.\n",
    "\n",
    "The next information we need is the number of movies and users in the dataset. Although we already know this from the dataset information, for didactic purposes we'll get them from the data itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943 -- Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings.user_id.unique())\n",
    "n_movies = len(ratings.movie_id.unique())\n",
    "\n",
    "print(f\"Number of users: {n_users} -- Number of movies: {n_movies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "\n",
    "Now we'll create the train and test sets that we will use to evaluate the performance of our system. 20% of each user ratings will be used for testing, and the remaining that will be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80000, 3), (20000, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_perc = 0.2\n",
    "\n",
    "# Initialize the train and test dataframes.\n",
    "train_set, test_set = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "# Check each user.\n",
    "for user_id in ratings.user_id.unique():\n",
    "    user_df = ratings[ratings.user_id == user_id].sample(\n",
    "        frac=1,\n",
    "        random_state=42\n",
    "    ) # select only samples of the actual user and shuffle the resulting dataframe\n",
    "    \n",
    "    n_entries = len(user_df)\n",
    "    n_test = int(round(test_perc * n_entries))\n",
    "    \n",
    "    test_set = pd.concat((test_set, user_df.tail(n_test)))\n",
    "    train_set = pd.concat((train_set, user_df.head(n_entries - n_test)))\n",
    "\n",
    "train_set = train_set.sample(frac=1).reset_index(drop=True)\n",
    "test_set = test_set.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a function to compute the *interactions matrix* of a given ratings dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interactions_matrix(r_mat, n_users, n_items):\n",
    "    iter_m = np.zeros((n_users, n_items))\n",
    "    \n",
    "    for _, user_id, movie_id, rating in r_mat.itertuples():\n",
    "        iter_m[user_id-1, movie_id-1] = rating\n",
    "    \n",
    "    return iter_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_m = build_interactions_matrix(ratings, n_users, n_movies)\n",
    "iter_m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory based approach\n",
    "\n",
    "In this post we'll build our system using the **memory based** approach, in which similarities between users/items are computed using the rating data itself. Therefore, the *i*-th row of an interactions matrix is considered as the **feature vector** of user *i*, while the *j*-th column of an interaction matrix is considered as the **feature vector** of item *j*.\n",
    "\n",
    "<figure style=\"display: block; margin-left: auto; margin-right: auto; width: 90%; text-align: center;\">\n",
    "  <img src=\"figures/memory_based.png\" alt=\"Feature vectors in CF memory-based approach\">\n",
    "  <figcaption>Feature vectors in CF memory-based approach</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity between two users is represented by some **distance measurement** between their feature vectors. Multiple measures, such as Pearson correlation and vector cosine are used for this. For example, the similarity between users $u$ and $u'$ can be computed using vector cosine as:\n",
    "$$\n",
    "sim(u, u') = cos(\\textbf{r}_u, \\textbf{r}_{u'}) = \n",
    "\\frac{\\textbf{r}_u \\textbf{.} \\textbf{r}_{u'}}{|\\textbf{r}_u||\\textbf{r}_{u'}|} =\n",
    "\\frac{\\sum_i r_{ui}r_{u'i}}{\\sqrt{\\sum_i r_{ui}^2}\\sqrt{\\sum_i r_{u'i}^2}}\n",
    "$$\n",
    "where $\\textbf{r}_u$ and $\\textbf{r}_{u'}$ are the feature vectors of users $u$ and $u'$, respectively, and $r_{ui}$ is a rating value given by user $u$ to item $i$. The same procedure is applied when computing the similarity between items $i$ and $i'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(interactions_matrix, kind=\"user\", eps=1e-9):\n",
    "    # takes rows as user features\n",
    "    if kind == \"user\":\n",
    "        similarity_matrix = interactions_matrix.dot(interactions_matrix.T)\n",
    "    # takes columns as item features\n",
    "    elif kind == \"item\":\n",
    "        similarity_matrix = interactions_matrix.T.dot(interactions_matrix)\n",
    "    norms = np.sqrt(similarity_matrix.diagonal()) + eps\n",
    "    return similarity_matrix / (norms[np.newaxis, :] * norms[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User similarity matrix shape: (943, 943)\n",
      "User similarity matrix sample:\n",
      "[[1.         0.16693098 0.04745954 0.06435782]\n",
      " [0.16693098 1.         0.11059132 0.17812119]\n",
      " [0.04745954 0.11059132 1.         0.34415072]\n",
      " [0.06435782 0.17812119 0.34415072 1.        ]]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Item similarity matrix shape: (1682, 1682)\n",
      "Item similarity matrix sample:\n",
      "[[1.         0.40238218 0.33024479 0.45493792]\n",
      " [0.40238218 1.         0.27306918 0.50257077]\n",
      " [0.33024479 0.27306918 1.         0.32486639]\n",
      " [0.45493792 0.50257077 0.32486639 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "u_sim = build_similarity_matrix(iter_m, kind=\"user\")\n",
    "i_sim = build_similarity_matrix(iter_m, kind=\"item\")\n",
    "\n",
    "print(f\"User similarity matrix shape: {u_sim.shape}\\nUser similarity matrix sample:\\n{u_sim[:4, :4]}\")\n",
    "print(\"-\" * 97)\n",
    "print(f\"Item similarity matrix shape: {i_sim.shape}\\nItem similarity matrix sample:\\n{i_sim[:4, :4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity matrix is a symmetric matrix with values in range 0 to 1. The diagonal elements contains the auto-similarities of all users/items, so all elements are equal to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "Now we are able to make predictions. Depending on which approach we have chosen for our system, we have two different objectives:\n",
    "\n",
    "1. If we choose the user-based approach, we'll infer a missing rating $r_{ui}$ of an user $u$ to an item $i$ by taking the normalized weighted sum of **all ratings of other users to this item**.\n",
    "\n",
    "$$\n",
    "r_{ui} = \\frac{\\sum_{u'} sim(u, u')r_{u'i}}{\\sum_{u'} |sim(u, u')|}\n",
    "$$\n",
    "\n",
    "2. If we choose the item-based approach instead, we'll infer a missing rating $r_{ui}$ of an user $u$ to an item $i$ by taking the normalized weighted sum of **all other ratings of this user to the other items**.\n",
    "\n",
    "$$\n",
    "r_{ui} = \\frac{\\sum_{i'} sim(i, i')r_{ui'}}{\\sum_{i'} |sim(i, i')|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Recommender class\n",
    "\n",
    "Let's build a *Recommender* class, that will do all the heavy lifting of compute/store the similarity matrices and make rating predictions for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users,\n",
    "        n_items,\n",
    "        r_mat,\n",
    "        kind=\"user\",\n",
    "        eps=1e-9,\n",
    "    ):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.kind = kind\n",
    "        self.eps = eps\n",
    "        self.iter_m = build_interactions_matrix(r_mat, self.n_users, self.n_items)\n",
    "        self.sim_m = build_similarity_matrix(self.iter_m, kind=self.kind)\n",
    "        self.predictions = self._predict_all()\n",
    "    \n",
    "    def _predict_all(self):\n",
    "        if self.kind == \"user\":\n",
    "            predictions = \\\n",
    "                self.sim_m.dot(self.iter_m) / np.abs(self.sim_m + self.eps).sum(axis=0)[:, np.newaxis]\n",
    "        elif self.kind == \"item\":\n",
    "            predictions = \\\n",
    "                self.iter_m.dot(self.sim_m) / np.abs(self.sim_m + self.eps).sum(axis=0)[np.newaxis, :]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based predictions sample:\n",
      "[[1.83706987 0.6257035  0.33869847 1.00876026]\n",
      " [1.5422442  0.27024912 0.23318095 0.48654518]\n",
      " [0.9610046  0.22919461 0.16521262 0.38923742]\n",
      " [1.2288292  0.27348381 0.20238746 0.47424947]]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "item-based predictions sample:\n",
      "[[0.97004593 0.88005233 0.88561114 0.94116817]\n",
      " [0.23553281 0.1252388  0.17800975 0.15055959]\n",
      " [0.08729475 0.0632449  0.0812641  0.06648524]\n",
      " [0.07542813 0.05258989 0.06783286 0.05653723]]\n"
     ]
    }
   ],
   "source": [
    "print(\"User-based predictions sample:\")\n",
    "print(Recommender(n_users, n_movies, train_set, kind=\"user\").predictions[:4, :4])\n",
    "print(\"-\" * 97)\n",
    "print(\"item-based predictions sample:\")\n",
    "print(Recommender(n_users, n_movies, train_set, kind=\"item\").predictions[:4, :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "Now it's time to assess the predictor performance. For this we'll use *Mean Squared Error* (MSE) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_predictions_df(preds_m, dataframe):\n",
    "    preds_v = []\n",
    "    for row_id, user_id, movie_id, _ in dataframe.itertuples():\n",
    "        preds_v.append(preds_m[user_id-1, movie_id-1])\n",
    "    preds_df = pd.DataFrame(data={\"user_id\": dataframe.user_id, \"movie_id\": dataframe.movie_id, \"rating\": preds_v})\n",
    "    return preds_df\n",
    "\n",
    "def get_mse(estimator, train_set, test_set):\n",
    "    train_preds = build_predictions_df(estimator.predictions, train_set)\n",
    "    test_preds = build_predictions_df(estimator.predictions, test_set)\n",
    "    \n",
    "    train_mse = mean_squared_error(train_set.rating, train_preds.rating)\n",
    "    test_mse = mean_squared_error(test_set.rating, test_preds.rating)\n",
    "    \n",
    "    return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based train MSE: 8.703104242707171 -- User-based test MSE: 8.914272669040075\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Item-based train MSE: 9.436480326757003 -- Item-based test MSE: 9.726712690862362\n"
     ]
    }
   ],
   "source": [
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"user\"),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"User-based train MSE: {train_mse} -- User-based test MSE: {test_mse}\")\n",
    "print(\"-\" * 97)\n",
    "\n",
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"item\"),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"Item-based train MSE: {train_mse} -- Item-based test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors\n",
    "\n",
    "At this point the rating predictions are computed using the ratings of either all users or all items. This means that even the users/items with low similarity scores will be acounted for the prediction computation. A better approach is to take an smaller subset of the most similar users/items to make a prediction. This technique is usually refered as *k-nearest neighbors*, or *KNN* algorithm.\n",
    "\n",
    "We'll adapt our Estimator class to use only the most similar users/items to make an prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users,\n",
    "        n_items,\n",
    "        r_mat,\n",
    "        k=40, # the number of neighbors to use when computing the similarity score\n",
    "        kind=\"user\",\n",
    "        eps=1e-9\n",
    "    ):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.kind = kind\n",
    "        self.eps = eps\n",
    "        self.iter_m = build_interactions_matrix(r_mat, self.n_users, self.n_items)\n",
    "        self.sim_m = build_similarity_matrix(self.iter_m, kind=self.kind)\n",
    "        self.k = k\n",
    "        self.predictions = self._predict_all()\n",
    "    \n",
    "    def _predict_all(self):\n",
    "        pred = np.empty_like(self.iter_m)\n",
    "        if self.kind == \"user\":\n",
    "            # An user has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for user_id, k_users in enumerate(sorted_ids):\n",
    "                pred[user_id, :] = self.sim_m[user_id, k_users].dot(self.iter_m[k_users, :])\n",
    "                pred[user_id, :] /= np.abs(self.sim_m[user_id, k_users] + self.eps).sum()\n",
    "        elif self.kind == \"item\":\n",
    "            # An item has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for item_id, k_items in enumerate(sorted_ids):\n",
    "                pred[:, item_id] = self.sim_m[item_id, k_items].dot(self.iter_m[:, k_items].T)\n",
    "                pred[:, item_id] /= np.abs(self.sim_m[item_id, k_items] + self.eps).sum()\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based train MSE: 5.490605431419921 -- User-based test MSE: 6.174640689172995\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Item-based train MSE: 4.985672850673028 -- Item-based test MSE: 5.713362919538134\n"
     ]
    }
   ],
   "source": [
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"user\"),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"User-based train MSE: {train_mse} -- User-based test MSE: {test_mse}\")\n",
    "print(\"-\" * 97)\n",
    "\n",
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"item\"),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"Item-based train MSE: {train_mse} -- Item-based test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this method alone can improve greatly our system's prediction power. Later in this post, we'll try leverage the effect of the number of neighbors to do a simple tunning in our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias subtraction\n",
    "\n",
    "Now we'll try to deal with the rating bias associated with an user or an item. The ideia here is that certain users may tend to always give high or low ratings to all movies, so the *relative difference* in ratings may be more important than the *absolute rating* values.\n",
    "\n",
    "For a user-based approach this methodology can be mathematically described as:\n",
    "\n",
    "$$\n",
    "r_{ui} = \\overline{r}_{u} + \\frac{\\sum_{u'} sim(u, u')(r_{u'i} - \\overline{r}_{u'})}{\\sum_{u'} |sum(u, u')|}\n",
    "$$\n",
    "\n",
    "where $\\overline{r}_{u}$ is the average rating given by user *u*, or for a item-based approach as:\n",
    "\n",
    "$$\n",
    "r_{ui} = \\overline{r}_{i} + \\frac{\\sum_{i'} sim(i, i')(r_{ui'} - \\overline{r}_{i'})}{\\sum_{i'} |sum(i, i')|}\n",
    "$$\n",
    "\n",
    "where $\\overline{r}_{i}$ is the average rating of item *i*\n",
    "\n",
    "Lets modify our *Recommender* class once more to include this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users,\n",
    "        n_items,\n",
    "        r_mat,\n",
    "        k=40,\n",
    "        kind=\"user\",\n",
    "        bias_sub=False,\n",
    "        eps=1e-9\n",
    "    ):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.kind = kind\n",
    "        self.iter_m = build_interactions_matrix(r_mat, self.n_users, self.n_items)\n",
    "        self.sim_m = build_similarity_matrix(self.iter_m, kind=self.kind)\n",
    "        self.bias_sub = bias_sub\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "        self.predictions = self._predict_all()\n",
    "    \n",
    "    def _predict_all(self):\n",
    "        pred = np.empty_like(self.iter_m)\n",
    "        if self.kind == \"user\":\n",
    "            # Computes the new interaction matrix if needed.\n",
    "            iter_m = self.iter_m\n",
    "            if self.bias_sub:\n",
    "                user_bias = self.iter_m.mean(axis=1)[:, np.newaxis]\n",
    "                iter_m -= user_bias\n",
    "            # An user has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for user_id, k_users in enumerate(sorted_ids):\n",
    "                pred[user_id, :] = self.sim_m[user_id, k_users].dot(iter_m[k_users, :])\n",
    "                pred[user_id, :] /= \\\n",
    "                    np.abs(self.sim_m[user_id, k_users] + self.eps).sum() + self.eps\n",
    "            if self.bias_sub:\n",
    "                pred += user_bias\n",
    "            \n",
    "        elif self.kind == \"item\":\n",
    "            # Computes the new interaction matrix if needed.\n",
    "            iter_m = self.iter_m\n",
    "            if self.bias_sub:\n",
    "                item_bias = self.iter_m.mean(axis=0)[np.newaxis, :]\n",
    "                iter_m -= item_bias\n",
    "            # An item has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for item_id, k_items in enumerate(sorted_ids):\n",
    "                pred[:, item_id] = self.sim_m[item_id, k_items].dot(iter_m[:, k_items].T)\n",
    "                pred[:, item_id] /= \\\n",
    "                    np.abs(self.sim_m[item_id, k_items] + self.eps).sum() + self.eps\n",
    "            if self.bias_sub:\n",
    "                pred += item_bias\n",
    "                \n",
    "        return pred.clip(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based train MSE: 5.685449266835428 -- User-based test MSE: 6.394565262018779\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Item-based train MSE: 5.4271747547608555 -- Item-based test MSE: 6.214109193478461\n"
     ]
    }
   ],
   "source": [
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"user\", bias_sub=True),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"User-based train MSE: {train_mse} -- User-based test MSE: {test_mse}\")\n",
    "print(\"-\" * 97)\n",
    "\n",
    "train_mse, test_mse = get_mse(\n",
    "    Recommender(n_users, n_movies, train_set, kind=\"item\", bias_sub=True),\n",
    "    train_set,\n",
    "    test_set\n",
    ")\n",
    "\n",
    "print(f\"Item-based train MSE: {train_mse} -- Item-based test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this methodology did not improved the results for this scenario, possibly due to the characteristics of the dataset, it can be effective with another dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning up\n",
    "\n",
    "There is one question left: how do we find the right number of similar users/items we should use when predicting a rating?\n",
    "\n",
    "The author of the [blog post](https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/) that we this post was based used the so-called [Elbow Method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)) to find the value of *k*. Although this is a fine methodology, I'm personally more inclined to use more programatic ways to achieve those kind of goals.\n",
    "\n",
    "If you thought of model hyperparameters search methods, like grid-search or random-search, then we are in the same line of thinking.\n",
    "\n",
    "*Scikit-learn* package already has some standart implementations of these methods based on *cross-validation scores*, but these are quite limited to a random search (using RandomSearchCV) or a full greedy search (using GridSearchCV). Although we could certainly implement our own parameters search routines, here I optioned to use the [*Optuna*](https://optuna.org/) package. It has a simple and powerful interface is a *must-use* tool for any *Machine Learning* practitioneer.\n",
    "\n",
    "We begin by define a *objective* function to be minimized. This function will be responsible for choosing the parameters to be used, instantiating the model with these parameters and evaluating the model's performance. Our use case is quite simple, as we have only two parameters (*k* and *bias_sub*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # The list of hyper-parameters we want to optmizer. For each one we define the bounds\n",
    "    # and the corresponding name.\n",
    "    k = trial.suggest_int(\"k\", 10, 200)\n",
    "    bias_sub = trial.suggest_categorical(\"bias_sub\", [False, True])\n",
    "\n",
    "    # Instantiating the model\n",
    "    model = Recommender(n_users, n_movies, train_set, kind=\"item\", k=k, bias_sub=bias_sub)\n",
    "    # Evaluating the performance\n",
    "    _, test_mse = get_mse(model, train_set, test_set)\n",
    "    return test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we defini our **study** object, that will be responsible for the hyperparameter search itself, as well as keep track of the optimization's history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-04 17:00:46,148] A new study created in memory with name: no-name-153c9c43-c251-4b5d-a812-39584b03d959\n",
      "[I 2024-04-04 17:00:47,260] Trial 0 finished with value: 6.473762308412302 and parameters: {'k': 76, 'bias_sub': True}. Best is trial 0 with value: 6.473762308412302.\n",
      "[I 2024-04-04 17:00:48,829] Trial 1 finished with value: 6.7379084182179865 and parameters: {'k': 121, 'bias_sub': True}. Best is trial 0 with value: 6.473762308412302.\n",
      "[I 2024-04-04 17:00:50,398] Trial 2 finished with value: 6.733040590487261 and parameters: {'k': 120, 'bias_sub': True}. Best is trial 0 with value: 6.473762308412302.\n",
      "[I 2024-04-04 17:00:52,595] Trial 3 finished with value: 6.9488357739069295 and parameters: {'k': 180, 'bias_sub': False}. Best is trial 0 with value: 6.473762308412302.\n",
      "[I 2024-04-04 17:00:54,864] Trial 4 finished with value: 6.9976594553898295 and parameters: {'k': 187, 'bias_sub': False}. Best is trial 0 with value: 6.473762308412302.\n",
      "[I 2024-04-04 17:00:55,852] Trial 5 finished with value: 6.3863913030458335 and parameters: {'k': 63, 'bias_sub': True}. Best is trial 5 with value: 6.3863913030458335.\n",
      "[I 2024-04-04 17:00:56,868] Trial 6 finished with value: 5.993720812245225 and parameters: {'k': 66, 'bias_sub': False}. Best is trial 6 with value: 5.993720812245225.\n",
      "[I 2024-04-04 17:00:58,154] Trial 7 finished with value: 6.580075306033448 and parameters: {'k': 93, 'bias_sub': True}. Best is trial 6 with value: 5.993720812245225.\n",
      "[I 2024-04-04 17:01:00,191] Trial 8 finished with value: 6.943021554867475 and parameters: {'k': 165, 'bias_sub': True}. Best is trial 6 with value: 5.993720812245225.\n",
      "[I 2024-04-04 17:01:01,415] Trial 9 finished with value: 6.543147647388037 and parameters: {'k': 87, 'bias_sub': True}. Best is trial 6 with value: 5.993720812245225.\n",
      "[I 2024-04-04 17:01:01,985] Trial 10 finished with value: 5.422950772402835 and parameters: {'k': 18, 'bias_sub': False}. Best is trial 10 with value: 5.422950772402835.\n",
      "[I 2024-04-04 17:01:02,482] Trial 11 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:02,979] Trial 12 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:03,538] Trial 13 finished with value: 5.399538980461102 and parameters: {'k': 17, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:04,283] Trial 14 finished with value: 5.684727596993318 and parameters: {'k': 38, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:05,109] Trial 15 finished with value: 5.735672275082821 and parameters: {'k': 42, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:05,618] Trial 16 finished with value: 5.344586591090668 and parameters: {'k': 11, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:06,411] Trial 17 finished with value: 5.745994973020386 and parameters: {'k': 43, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:08,138] Trial 18 finished with value: 6.616389712586264 and parameters: {'k': 135, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:08,855] Trial 19 finished with value: 5.649025695836072 and parameters: {'k': 35, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:09,760] Trial 20 finished with value: 5.876435102661271 and parameters: {'k': 55, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:10,321] Trial 21 finished with value: 5.399538980461102 and parameters: {'k': 17, 'bias_sub': False}. Best is trial 11 with value: 5.342331173458453.\n",
      "[I 2024-04-04 17:01:10,838] Trial 22 finished with value: 5.341853273407236 and parameters: {'k': 12, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:11,494] Trial 23 finished with value: 5.558403089977984 and parameters: {'k': 28, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:12,347] Trial 24 finished with value: 5.8277568958770845 and parameters: {'k': 50, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:12,845] Trial 25 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:13,502] Trial 26 finished with value: 5.558403089977984 and parameters: {'k': 28, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:14,142] Trial 27 finished with value: 5.533477656928119 and parameters: {'k': 26, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:15,067] Trial 28 finished with value: 5.89947844501077 and parameters: {'k': 57, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:16,121] Trial 29 finished with value: 6.025426844578749 and parameters: {'k': 69, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:18,024] Trial 30 finished with value: 6.7496053394490545 and parameters: {'k': 152, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:18,543] Trial 31 finished with value: 5.341853273407236 and parameters: {'k': 12, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:19,207] Trial 32 finished with value: 5.570183414279416 and parameters: {'k': 29, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:19,704] Trial 33 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:21,162] Trial 34 finished with value: 6.672897632354633 and parameters: {'k': 109, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:22,320] Trial 35 finished with value: 6.137544584322953 and parameters: {'k': 81, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:23,142] Trial 36 finished with value: 5.780889568046984 and parameters: {'k': 46, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:23,757] Trial 37 finished with value: 6.049608119629455 and parameters: {'k': 23, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:24,495] Trial 38 finished with value: 5.672155194146348 and parameters: {'k': 37, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:25,092] Trial 39 finished with value: 6.028966460803951 and parameters: {'k': 21, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:26,146] Trial 40 finished with value: 6.025426844578749 and parameters: {'k': 69, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:26,651] Trial 41 finished with value: 5.344586591090668 and parameters: {'k': 11, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:27,159] Trial 42 finished with value: 5.344586591090668 and parameters: {'k': 11, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:27,822] Trial 43 finished with value: 5.570183414279416 and parameters: {'k': 29, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:30,185] Trial 44 finished with value: 7.057302650194999 and parameters: {'k': 196, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:30,898] Trial 45 finished with value: 5.63377066886556 and parameters: {'k': 34, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:31,487] Trial 46 finished with value: 6.017699491576731 and parameters: {'k': 20, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:32,790] Trial 47 finished with value: 6.271299377619003 and parameters: {'k': 95, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:33,351] Trial 48 finished with value: 5.399538980461102 and parameters: {'k': 17, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:34,220] Trial 49 finished with value: 5.836941901186445 and parameters: {'k': 51, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:35,893] Trial 50 finished with value: 6.5774087114838675 and parameters: {'k': 130, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:36,408] Trial 51 finished with value: 5.341853273407236 and parameters: {'k': 12, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:36,904] Trial 52 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:37,489] Trial 53 finished with value: 5.445817076679518 and parameters: {'k': 20, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:38,226] Trial 54 finished with value: 5.672155194146348 and parameters: {'k': 37, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:38,787] Trial 55 finished with value: 5.399538980461102 and parameters: {'k': 17, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:39,479] Trial 56 finished with value: 6.138302946417691 and parameters: {'k': 32, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:40,274] Trial 57 finished with value: 5.735672275082821 and parameters: {'k': 42, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:40,898] Trial 58 finished with value: 5.472537049823912 and parameters: {'k': 22, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:41,442] Trial 59 finished with value: 5.372857358818758 and parameters: {'k': 15, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:43,529] Trial 60 finished with value: 6.880023613697107 and parameters: {'k': 170, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:44,058] Trial 61 finished with value: 5.348596930240617 and parameters: {'k': 13, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:44,557] Trial 62 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:45,186] Trial 63 finished with value: 5.5203668606152965 and parameters: {'k': 25, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:45,833] Trial 64 finished with value: 5.533477656928119 and parameters: {'k': 26, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:46,427] Trial 65 finished with value: 5.399538980461102 and parameters: {'k': 17, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:47,130] Trial 66 finished with value: 5.621767764696275 and parameters: {'k': 33, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:48,095] Trial 67 finished with value: 5.939915643221463 and parameters: {'k': 61, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:48,869] Trial 68 finished with value: 5.72345516185488 and parameters: {'k': 41, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:49,500] Trial 69 finished with value: 6.062208835174823 and parameters: {'k': 24, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:50,037] Trial 70 finished with value: 5.3562674073328465 and parameters: {'k': 14, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:50,548] Trial 71 finished with value: 5.344586591090668 and parameters: {'k': 11, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:51,067] Trial 72 finished with value: 5.344586591090668 and parameters: {'k': 11, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:51,663] Trial 73 finished with value: 5.459341445506474 and parameters: {'k': 21, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:52,332] Trial 74 finished with value: 5.570183414279416 and parameters: {'k': 29, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:52,832] Trial 75 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:53,388] Trial 76 finished with value: 5.382949280903645 and parameters: {'k': 16, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:54,233] Trial 77 finished with value: 5.8039113858526346 and parameters: {'k': 48, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:54,920] Trial 78 finished with value: 5.601433016472603 and parameters: {'k': 31, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:55,540] Trial 79 finished with value: 5.4881839267490395 and parameters: {'k': 23, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:56,115] Trial 80 finished with value: 5.996594831224809 and parameters: {'k': 18, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:56,616] Trial 81 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:57,164] Trial 82 finished with value: 5.372857358818758 and parameters: {'k': 15, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:57,664] Trial 83 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:58,299] Trial 84 finished with value: 5.5203668606152965 and parameters: {'k': 25, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:58,886] Trial 85 finished with value: 5.445817076679518 and parameters: {'k': 20, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:01:59,619] Trial 86 finished with value: 5.66115922630519 and parameters: {'k': 36, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:00,294] Trial 87 finished with value: 5.570183414279416 and parameters: {'k': 29, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:01,736] Trial 88 finished with value: 6.370067987227846 and parameters: {'k': 106, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:02,283] Trial 89 finished with value: 5.372857358818758 and parameters: {'k': 15, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:02,880] Trial 90 finished with value: 5.459341445506474 and parameters: {'k': 21, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:03,381] Trial 91 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:05,257] Trial 92 finished with value: 6.73456106977193 and parameters: {'k': 150, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:05,808] Trial 93 finished with value: 5.3562674073328465 and parameters: {'k': 14, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:06,310] Trial 94 finished with value: 5.342331173458453 and parameters: {'k': 10, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:06,890] Trial 95 finished with value: 5.434930583981397 and parameters: {'k': 19, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:07,543] Trial 96 finished with value: 5.541716977681339 and parameters: {'k': 27, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:08,101] Trial 97 finished with value: 5.970840301149119 and parameters: {'k': 16, 'bias_sub': True}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:08,724] Trial 98 finished with value: 5.503976797247932 and parameters: {'k': 24, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n",
      "[I 2024-04-04 17:02:09,425] Trial 99 finished with value: 5.621767764696275 and parameters: {'k': 33, 'bias_sub': False}. Best is trial 22 with value: 5.341853273407236.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "# Here the parameter search effectively begins.\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can retrieve the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "  - k = 12\n",
      "  - bias_sub = False\n"
     ]
    }
   ],
   "source": [
    "best_k = study.best_params[\"k\"]\n",
    "best_bias_sub = study.best_params[\"bias_sub\"]\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(f\"  - k = {best_k}\")\n",
    "print(f\"  - bias_sub = {best_bias_sub}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even plot a *convergence plot*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13434/616175072.py:1: ExperimentalWarning: plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.\n",
      "  optuna.visualization.matplotlib.plot_optimization_history(study);\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.matplotlib.plot_optimization_history(study);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item recommendation\n",
    "\n",
    "Now that we have defined our parameters, we can make our system do what it is suposed to: recommend items. There are many ways to acomplish this, but I optioned to go for the simple way and just recommend items most similar to a item using a *item-based* system.\n",
    "\n",
    "Let's make the last modification to our *Recommender* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users,\n",
    "        n_items,\n",
    "        r_mat,\n",
    "        k=40,\n",
    "        kind=\"user\",\n",
    "        bias_sub=False,\n",
    "        eps=1e-9\n",
    "    ):\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.kind = kind\n",
    "        self.iter_m = build_interactions_matrix(r_mat, self.n_users, self.n_items)\n",
    "        self.sim_m = build_similarity_matrix(self.iter_m, kind=self.kind)\n",
    "        self.bias_sub = bias_sub\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "        self.predictions = self._predict_all()\n",
    "    \n",
    "    def _predict_all(self):\n",
    "        pred = np.empty_like(self.iter_m)\n",
    "        if self.kind == \"user\":\n",
    "            # Computes the new interaction matrix if needed.\n",
    "            iter_m = self.iter_m\n",
    "            if self.bias_sub:\n",
    "                user_bias = self.iter_m.mean(axis=1)[:, np.newaxis]\n",
    "                iter_m -= user_bias\n",
    "            # An user has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for user_id, k_users in enumerate(sorted_ids):\n",
    "                pred[user_id, :] = self.sim_m[user_id, k_users].dot(iter_m[k_users, :])\n",
    "                pred[user_id, :] /= np.abs(self.sim_m[user_id, k_users]).sum() + self.eps\n",
    "            if self.bias_sub:\n",
    "                pred += user_bias\n",
    "            \n",
    "        elif self.kind == \"item\":\n",
    "            # Computes the new interaction matrix if needed.\n",
    "            iter_m = self.iter_m\n",
    "            if self.bias_sub:\n",
    "                item_bias = self.iter_m.mean(axis=0)[np.newaxis, :]\n",
    "                iter_m -= item_bias\n",
    "            # An item has the higher similarity score with itself,\n",
    "            # so we skip the first element.\n",
    "            sorted_ids = np.argsort(-self.sim_m)[:, 1:self.k+1]\n",
    "            for item_id, k_items in enumerate(sorted_ids):\n",
    "                pred[:, item_id] = self.sim_m[item_id, k_items].dot(iter_m[:, k_items].T)\n",
    "                pred[:, item_id] /= np.abs(self.sim_m[item_id, k_items]).sum() + self.eps\n",
    "            if self.bias_sub:\n",
    "                pred += item_bias\n",
    "                \n",
    "        return pred.clip(0, 5)\n",
    "    \n",
    "    def get_top_recomendations(self, item_id, n=6):\n",
    "        if self.kind == \"user\":\n",
    "            # For an user-based system, only similarities between users were computed.\n",
    "            # This strategy will not be covered in this post, but a solution to this\n",
    "            # could be of finding the top better rated items of similiar users.\n",
    "            # I'll leave this exercise to you =]\n",
    "            pass\n",
    "        if self.kind == \"item\":\n",
    "            sim_row = self.sim_m[item_id - 1, :]\n",
    "            # once again, we skip the first item for obviouos reasons.\n",
    "            items_idxs = np.argsort(-sim_row)[1:n+1]\n",
    "            similarities = sim_row[items_idxs]\n",
    "            return items_idxs + 1, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a method to return the $n$ most similar items to a given item. Now, we just need to buil our model with the parameters found previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2755618709089025, 3.2546408150520767)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_model = Recommender(\n",
    "    n_users, \n",
    "    n_movies, \n",
    "    ratings, # the model will be built on the full dataset now\n",
    "    k=best_k, \n",
    "    kind=\"item\", \n",
    "    bias_sub=best_bias_sub\n",
    ")\n",
    "get_mse(rs_model, train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also define two functions: one that maps a movie title to an id and other that maps a list of movie ids into a list of movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title2id(mapper_df, movie_title):\n",
    "    return mapper_df.loc[mapper_df.movie_title == movie_title, \"movie_title\"].index.values[0]\n",
    "\n",
    "def ids2title(mapper_df, ids_list):\n",
    "    titles = []\n",
    "    for id in ids_list:\n",
    "        titles.append(mapper_df.loc[id, \"movie_title\"])\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those functions need a dataframe with the movies ids and titles, that will act as a mapper. So we'll load the **u.item** file from the dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Mat' i syn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>B. Monkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>Sliding Doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>You So Crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Scream of Stone (Schrei aus Stein)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 movie_title\n",
       "movie_id                                    \n",
       "1                                  Toy Story\n",
       "2                                  GoldenEye\n",
       "3                                 Four Rooms\n",
       "4                                 Get Shorty\n",
       "5                                    Copycat\n",
       "...                                      ...\n",
       "1678                              Mat' i syn\n",
       "1679                               B. Monkey\n",
       "1680                           Sliding Doors\n",
       "1681                            You So Crazy\n",
       "1682      Scream of Stone (Schrei aus Stein)\n",
       "\n",
       "[1682 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns names\n",
    "movies_mapper_cols = [\n",
    "    \"movie_id\", \n",
    "    \"movie_title\", \n",
    "    \"release_date\", \n",
    "    \"video_release_date\", \n",
    "    \"IMDb_URL\", \n",
    "    \"unknown\",\n",
    "    \"Action\",\n",
    "    \"Adventure\",\n",
    "    \"Animation\",\n",
    "    \"Childrens\",\n",
    "    \"Comedy\",\n",
    "    \"Crime\",\n",
    "    \"Documentary\",\n",
    "    \"Drama\",\n",
    "    \"Fantasy\",\n",
    "    \"Film_Noir\",\n",
    "    \"Horror\",\n",
    "    \"Musical\",\n",
    "    \"Mystery\",\n",
    "    \"Romance\",\n",
    "    \"Sci_Fi\",\n",
    "    \"Thriller\",\n",
    "    \"War\",\n",
    "    \"Western\" \n",
    "]\n",
    "movies_mapper = pd.read_csv(\n",
    "    \"ml-100k/u.item\",\n",
    "    sep=\"|\",\n",
    "    encoding=\"latin\",\n",
    "    names=movies_mapper_cols,\n",
    "    usecols=[\"movie_id\", \"movie_title\"], # we only need these columns\n",
    "    index_col=\"movie_id\"\n",
    ")\n",
    "# Remove movies release years from titles\n",
    "movies_mapper[\"movie_title\"] = movies_mapper[\"movie_title\"].apply(\n",
    "    lambda title: re.sub(\"\\(\\d{4}\\)\", \"\", title).strip()\n",
    ")\n",
    "movies_mapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make our recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_recommendations(model, mapper, movie_title):\n",
    "    ids_list, similarities = rs_model.get_top_recomendations(title2id(mapper, movie_title))\n",
    "    titles = ids2title(movies_mapper, ids_list)\n",
    "    for title, similarity in zip (titles, similarities):\n",
    "        print(f\"{similarity:.2f} -- {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73 -- Star Wars\n",
      "0.70 -- Return of the Jedi\n",
      "0.69 -- Independence Day (ID4)\n",
      "0.66 -- Rock, The\n",
      "0.64 -- Mission: Impossible\n",
      "0.64 -- Willy Wonka and the Chocolate Factory\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Toy Story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71 -- Batman\n",
      "0.64 -- Batman Forever\n",
      "0.62 -- Stargate\n",
      "0.62 -- Die Hard: With a Vengeance\n",
      "0.61 -- True Lies\n",
      "0.61 -- Crow, The\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Batman Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66 -- Under Siege\n",
      "0.62 -- Top Gun\n",
      "0.62 -- True Lies\n",
      "0.62 -- Batman\n",
      "0.60 -- Stargate\n",
      "0.60 -- Cliffhanger\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"GoldenEye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70 -- Star Wars\n",
      "0.67 -- Godfather: Part II, The\n",
      "0.65 -- Fargo\n",
      "0.63 -- Return of the Jedi\n",
      "0.59 -- Raiders of the Lost Ark\n",
      "0.58 -- Pulp Fiction\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Godfather, The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 -- Dumb & Dumber\n",
      "0.49 -- Ace Ventura: Pet Detective\n",
      "0.45 -- Hot Shots! Part Deux\n",
      "0.44 -- Brady Bunch Movie, The\n",
      "0.44 -- Young Guns II\n",
      "0.43 -- Tommy Boy\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Billy Madison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 -- Aladdin\n",
      "0.69 -- Beauty and the Beast\n",
      "0.68 -- Forrest Gump\n",
      "0.66 -- Jurassic Park\n",
      "0.65 -- E.T. the Extra-Terrestrial\n",
      "0.65 -- Empire Strikes Back, The\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Lion King, The\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88 -- Return of the Jedi\n",
      "0.76 -- Raiders of the Lost Ark\n",
      "0.75 -- Empire Strikes Back, The\n",
      "0.73 -- Toy Story\n",
      "0.70 -- Godfather, The\n",
      "0.69 -- Independence Day (ID4)\n"
     ]
    }
   ],
   "source": [
    "print_recommendations(rs_model, movies_mapper, \"Star Wars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "What can we say about those recommendations?\n",
    "\n",
    "Some recommendations are pretty good. For example, \"Batman Returns\" is similar to other Batman movies, that's for sure. \"The Lion King\" is similar to \"Aladdin\" and \"Beauty and the Beast\" (Disney movies). \"Star Wars\" is similar to other Star Wars movies.\n",
    "\n",
    "Some of them does not make much sense. \"Toy Story\" does not seems so similar to \"The Rock\" and \"Mission: Impossible\" to me. \"The Lion King\" is not so similar to \"Jurassic Park\" too, aside that both have animals as their main feature. And I certainly cannot understand the similarity between \"The Godfather\" movies with \"Star Wars\" movies.\n",
    "\n",
    "Personal conclusions aside, there are some well-known advantages of memory-based Collaborative Filtering systems in literature. Some of them are:\n",
    "\n",
    "* **Explainability of the results:** which is an important aspect of recommendations systems;\n",
    "* **Easy of creation and use:** all methodology is purely based in manipulations of the interactions matrix;\n",
    "* **Content-independence of the items being recommended:** no descriptions, nor genre definitions, nor color definitions, nor size definition, etc. No metadata at all.\n",
    "\n",
    "But nothing in this world is perfect, and this approach suffers from disadvantages too. Some of them are:\n",
    "\n",
    "* **Performance decreases when data gets more sparse:** which occurs frequently with web-related items;\n",
    "* **Adding new items becomes more complicated:** since the data sctructures representations as an interactions matrix relies on a specific *vector space*, adding new items requires inclusion of the new item and the re-insertion of all elements in the structure.\n",
    "* **Recommendations tend to be already popular:** items from the so-called [long-tail](https://en.wikipedia.org/wiki/Long_tail) section might get ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook of this post can found [here](https://github.com/TheCamilovisk/DSNotebooks/blob/main/RecommenderSystems/CollaborativeFilteringMemoryBased.ipynb).\n",
    "\n",
    "A great thanks to [Ethan Rosenthal](https://www.ethanrosenthal.com/#), the author of the [blog post](https://www.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/) which of the ideas and concepts presented here were based on.\n",
    "\n",
    "Other usefull links:\n",
    "* [Wikipedia's article on Collaborative Filtering.](https://realpython.com/build-recommendation-engine-collaborative-filtering/#model-based)\n",
    "* [Real Python post on Collaborative Filtering.](https://realpython.com/build-recommendation-engine-collaborative-filtering/#model-based)\n",
    "* [Data Flair Recommendations System Project in R.](https://data-flair.training/blogs/data-science-r-movie-recommendation/)\n",
    "* [Optuna page.](https://optuna.org/)\n",
    "\n",
    "Books of interest:\n",
    "* [Mining of Massive Datasets](https://www.amazon.com.br/dp/1107077230/?tag=n) by Jure Leskovec, Anand Rajaraman, Jeff Ullman\n",
    "* [Programming Collective Intelligence](https://www.amazon.com.br/dp/0596529325/?tag=n) by Toby Segaran\n",
    "\n",
    "Thanks for reading to the end, and stay tuned for new posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
